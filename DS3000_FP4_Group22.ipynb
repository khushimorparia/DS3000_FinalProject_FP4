{
  "cells":[
    {
      "cell_type":"markdown",
      "source":[
        "<center> <h2> DS 3000 - Fall 2021<\/h2> <\/center>\n",
        "<center> <h3> DS Report <\/h3> <\/center>"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "<center> <h3> Prediction Countries' Education Levels <\/h3> <\/center>\n",
        "<center><h4>Priyanka Lal, Khushi Morparia, Katerina Thano<\/h4><\/center>"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "  "
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "#### Executive Summary:\n",
        "\n",
        "Education is a critical measure of a country’s development and is related to population, GDP, government spending, and employment, among others. For our project, we decided to look at multiple factors regarding education from 1970 to 2020 in countries around the world in order to quantify education levels and predict trends in them. We obtained all of our data from the World Bank and condensed it into one dataset. We used a line graph, bubble plot, box-and-whisker plot, and choropleth map to visualize our data. We then split the dataset and trained Linear, Lasso, and Support Vector Machine regressions on the dataset. We used feature engineering (normalization and scaling) to improve SVM, which was the algorithm that worked the best for our data. Lastly, we used hyperparameter tuning to optimize our model. Although we analyzed education for different countries in this project, it is important to note that our perspective is a very basic look at education and should not be used solely to understand education levels and their impact in the world.\n"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "## Outline\n",
        "1. <a href='#1'>INTRODUCTION<\/a>\n",
        "2. <a href='#2'>METHOD<\/a>\n",
        "3. <a href='#3'>RESULTS<\/a>\n",
        "4. <a href='#4'>DISCUSSION<\/a>"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "<a id=\"1\"><\/a>\n",
        "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "## 1. INTRODUCTION"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "<h4>Problem Statement<\/h4>\n",
        "\n",
        "When determining the amount of education a certain person or place has, a clear problem arises - there is no concrete way to quantify this. Is the education of a country determined by the number of children in school? Or is it their college graduation rate? What about the number of people in the labor force, or government expenditure on education? When it comes down to it, these factors all weigh on how educated a country is - or in other terms, their “education score.” Our project calculates the education score of a country in relation to labor force participation rate, pupil-teacher ratio, progression to secondary school, number of children out of primary school, and government expenditure on education. We want to learn an efficient way to calculate education scores as well as predict what the education level of a particular country will be in the future based on its past trends and performance.\n",
        "\n",
        "<h4>Significance of the Problem<\/h4>\n",
        "\n",
        "It is imperative that we tackle this problem as the level of education of a country is an important measure to consider when examining and ranking areas. Furthermore, examining this problem could lead to potential new insights, such as which countries are better suited to produce goods in. After all, countries with higher amounts of educated people are more likely to have a powerful workforce, which can lead to a higher level of production.\n",
        "\n",
        "<h4>Questions<\/h4>\n",
        "Our group tackled multiple data analysis questions in this project. Given our problem of determining how to calculate and predict education scores and the significance of using this measure, some questions we answered are: how much does each factor weigh into the calculation of an education score? What is the most effective way to handle missing values in our data set? And which algorithm (linear regression, support vector machines, or lasso regression) aligns best with our dataset?\n",
        "\n"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "<a id=\"2\"><\/a>\n",
        "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "## 2. METHOD"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "### 2.1. Data Acquisition\n",
        "Our data came from the World Bank datasets on data.worldbank.org. Links to each dataset are provided below:\n",
        "\n",
        "- Population ages 0-14, female https:\/\/data.worldbank.org\/indicator\/SP.POP.0014.FE.IN\n",
        "- Population ages 0-14, male (% of male population) https:\/\/data.worldbank.org\/indicator\/SP.POP.0014.MA.ZS \n",
        "- Literacy rate, adult female (% of females ages 15 and above) https:\/\/data.worldbank.org\/indicator\/SE.ADT.LITR.FE.ZS?view=chart\n",
        "- Literacy rate, adult male (% of male ages 15 and above) https:\/\/data.worldbank.org\/indicator\/SE.ADT.LITR.MA.ZS?view=chart \n",
        "- Labor force participation rate, female (% of female population ages 15+)  https:\/\/data.worldbank.org\/indicator\/SL.TLF.CACT.FE.ZS?view=chart\n",
        "- Labor force participation rate, male (% of male population ages 15+) https:\/\/data.worldbank.org\/indicator\/SL.TLF.CACT.MA.ZS?view=chart \n",
        "- Children out of school, primary, female https:\/\/data.worldbank.org\/indicator\/SE.PRM.UNER.FE?view=chart\n",
        "- Children out of school, primary, male https:\/\/data.worldbank.org\/indicator\/SE.PRM.UNER.MA?view=chart\n",
        "- Government Expenditure total:  https:\/\/data.worldbank.org\/indicator\/SE.XPD.TOTL.GD.ZS?view=chart \n",
        "- Progression to secondary school (female) https:\/\/data.worldbank.org\/indicator\/SE.SEC.PROG.FE.ZS?view=chart \n",
        "- Progression to secondary school (male) https:\/\/data.worldbank.org\/indicator\/SE.SEC.PROG.MA.ZS?view=chart "
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "### 2.2. Data Analysis\n",
        "\n",
        "Our outcome variable is an education score calculated from our feature variables. The feature variables are the country, country code, year, population, male and female participation in the labor force, government expenditure on education, pupil-teacher ratio, rate of male and female progression to secondary school, and rate of male and female children out of school. These are important predictors because they are related to education and directly describe the quality and quantity of education in a country.\n",
        "\n",
        "\n",
        "This is a supervised machine learning problem because the data is labeled and can be used to train models. It is not an unlabeled dataset that needs to be clustered and analyzed, as would be the case for unsupervised machine learning. The sub-category of the learning task is regression, as the outcome variable is a continuous education score.\n",
        "\n",
        "\n",
        "The four machine learning algorithms we are going to use are linear regression, lasso regression, Ridge, and KNN regression\n",
        "Linear regression is an algorithm that predicts trends using a linear equation. In this project, it assumes that there is a linear trend in educational levels across the years for each country, which is likely false because of the number of extraneous factors that go into the educational level. However, it is still appropriate for our data because it is the most basic regression algorithm and offers a baseline to compare the others to.\n",
        "Lasso regression uses variable selection and regularization to predict trends which makes it more accurate and interpretable than linear regression. It assumes that there is high collinearity which is definitely true for our dataset since our features are interconnected. Therefore, it is appropriate for our dataset.\n",
        "Ridge Regression is used to analyze multiple regression data that contains multicollinearity. Ridge regression reduces standard errors by adding a degree of bias to the regression estimates. This is beneficial for analysis as it eliminates any unwanted correlation between our independent factors. \n",
        "KNN regression is a method that approximates the association between independent variables and their outcome by averaging the observations in the same “neighborhood”. This aids in the analysis by estimating how much the various factors and education scores are associated.\n"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "<a id=\"3\"><\/a>\n",
        "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "## 3. RESULTS"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "### 3.1. Data Wrangling\n",
        "In this section, you should do the following and explain why you are doing what you are doing. For each, you should include your code in a cell, followed by a sample output. For instance, if you are one-hot encoding one of your variables, you should first describe what it is and why you are doing it. You should then include your code in a cell, and the sample output should be available as well.\n",
        "\n",
        "Do at least three of the following:\n",
        "* Perform simple data cleaning (delete extra columns, deal with NA values, etc.)\n",
        "* Perform data wrangling to get your features and target values (e.g., grouping your dataframe by columns, applying functions to format dataframes, etc.)\n",
        "* Preprocess your variables (e.g., scaling\/transforming feature variables to normalize them)\n",
        "* Perform feature extraction (dummy variables, new features from existing features, etc.)"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "import pandas as pd\n",
        "m_out_of_school = pd.read_csv(\"https:\/\/raw.githubusercontent.com\/khushimorparia\/DS3000_FinalProject_FP4\/20c8fb03970a88a7c6f439d2e7428c4338816906\/children%20out%20of%20school%20male%20CSV.csv\")\n",
        "f_out_of_school = pd.read_csv(\"https:\/\/raw.githubusercontent.com\/khushimorparia\/DS3000_FinalProject_FP4\/20c8fb03970a88a7c6f439d2e7428c4338816906\/children%20out%20of%20school%20primary%20fmle%20CSV.csv\")\n",
        "f_pop = pd.read_csv(\"https:\/\/raw.githubusercontent.com\/khushimorparia\/DS3000_FinalProject_FP4\/20c8fb03970a88a7c6f439d2e7428c4338816906\/population%200-14%20female%20CSV.csv\")\n",
        "m_pop = pd.read_csv(\"https:\/\/raw.githubusercontent.com\/khushimorparia\/DS3000_FinalProject_FP4\/20c8fb03970a88a7c6f439d2e7428c4338816906\/total%20population%20male%200-14.csv\")\n",
        "gov_expenditure = pd.read_csv(\"https:\/\/raw.githubusercontent.com\/khushimorparia\/DS3000_FinalProject_FP4\/20c8fb03970a88a7c6f439d2e7428c4338816906\/govt%20expenditure%20on%20education%20CSV.csv\")\n",
        "f_labor_participation = pd.read_csv(\"https:\/\/raw.githubusercontent.com\/khushimorparia\/DS3000_FinalProject_FP4\/20c8fb03970a88a7c6f439d2e7428c4338816906\/labor%20force%20participation%20CSV.csv\")\n",
        "m_labor_participation = pd.read_csv(\"https:\/\/raw.githubusercontent.com\/khushimorparia\/DS3000_FinalProject_FP4\/20c8fb03970a88a7c6f439d2e7428c4338816906\/male%20labor%20participation%20rate%20good%20CSV.csv\")\n",
        "f_progression_secondary = pd.read_csv(\"https:\/\/raw.githubusercontent.com\/khushimorparia\/DS3000_FinalProject_FP4\/20c8fb03970a88a7c6f439d2e7428c4338816906\/progression%20to%20secondary%20school%20fmale%20CSV.csv\")\n",
        "m_progression_secondary = pd.read_csv(\"https:\/\/raw.githubusercontent.com\/khushimorparia\/DS3000_FinalProject_FP4\/main\/progression%20to%20secondary%20school%20male%20CSV.csv\")\n",
        "pupil_teacher = pd.read_csv(\"https:\/\/raw.githubusercontent.com\/khushimorparia\/DS3000_FinalProject_FP4\/main\/pupil-teacher%20ratio%20CSV.csv\")"
      ],
      "execution_count":88,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "def replace(df):\n",
        "    for row in range(df.shape[0]):\n",
        "        num_nan = df.iloc[row,2:df.shape[1]].isnull().sum().sum()\n",
        "        if num_nan < (df.shape[1] - 12):\n",
        "            median = df.iloc[row,2:df.shape[1]].median()\n",
        "            df.iloc[row,2:df.shape[1]] = df.iloc[row,2:df.shape[1]].fillna(median)\n",
        "    df.dropna(inplace=True)"
      ],
      "execution_count":89,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "replace(m_out_of_school)\n",
        "replace(f_out_of_school)\n",
        "replace(m_pop)\n",
        "replace(f_pop)\n",
        "replace(m_labor_participation)\n",
        "replace(f_labor_participation)\n",
        "replace(gov_expenditure)\n",
        "replace(pupil_teacher)\n",
        "replace(f_progression_secondary)\n",
        "replace(m_progression_secondary)"
      ],
      "execution_count":90,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "def reshape(feature_name, df):\n",
        "    df=pd.melt(df, id_vars =['Country Name', 'Country Code'], \n",
        "                          value_vars =['1970', '1971', '1972', '1973', '1974', '1975',\n",
        "                                      '1976', '1977', '1978', '1979', '1980', '1981',\n",
        "                                      '1982', '1983', '1984', '1985', '1986', '1987',\n",
        "                                      '1988', '1989', '1990', '1991', '1992', '1993',\n",
        "                                      '1994', '1995', '1996', '1997', '1998', '1999',\n",
        "                                      '2000', '2001', '2002', '2003', '2004', '2005',\n",
        "                                      '2006', '2007', '2008', '2009', '2010', '2011',\n",
        "                                      '2012', '2013', '2014', '2015', '2016', '2017',\n",
        "                                      '2018', '2019', '2020'])\n",
        "    df.rename(columns={'Country Name':'country_name', 'Country Code':'country_code', 'variable':'year', 'value':feature_name}, inplace=True)\n",
        "    return df"
      ],
      "execution_count":91,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "m_out_of_school=reshape('m_children_out_of_school', m_out_of_school)\n",
        "f_out_of_school=reshape('f_children_out_of_school', f_out_of_school)\n",
        "m_pop=reshape('m_pop', m_pop)\n",
        "f_pop=reshape('f_pop', f_pop)\n",
        "m_labor_participation=reshape('m_labor_force_participation_rate', m_labor_participation)\n",
        "f_labor_participation=reshape('f_labor_force_participation_rate', f_labor_participation)\n",
        "gov_expenditure=reshape('govt_expenditure_education', gov_expenditure)\n",
        "pupil_teacher=reshape('pupil_teacher_ratio', pupil_teacher)\n",
        "f_progression_secondary=reshape('f_progression_to_secondary_school', f_progression_secondary)\n",
        "m_progression_secondary=reshape('m_progression_to_secondary_school', m_progression_secondary)"
      ],
      "execution_count":92,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "def merge(df1, df2):\n",
        "    return pd.merge(df1, df2, on=[\"country_code\", \"country_name\", \"year\"], how=\"left\")\n",
        "\n",
        "merged=merge(m_out_of_school, f_out_of_school)\n",
        "merged=merge(merged, m_pop)\n",
        "merged=merge(merged, f_pop)\n",
        "merged=merge(merged, m_labor_participation)\n",
        "merged=merge(merged, f_labor_participation)\n",
        "merged=merge(merged, gov_expenditure)\n",
        "merged=merge(merged, pupil_teacher)\n",
        "merged=merge(merged, f_progression_secondary)\n",
        "merged=merge(merged, m_progression_secondary)"
      ],
      "execution_count":93,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "row=0\n",
        "while(row < merged.shape[0]):\n",
        "        num_nan = merged.iloc[row,2:merged.shape[1]].isnull().sum().sum()\n",
        "        if (num_nan > 0):\n",
        "            country = merged.iloc[row,0]\n",
        "            merged.set_index(\"country_name\",inplace=True)\n",
        "            merged.drop(index=country, inplace=True)\n",
        "            merged.reset_index(inplace=True)\n",
        "        else:\n",
        "            row+=1"
      ],
      "execution_count":94,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "merged[\"f_out_of_school_rate\"] = merged[\"f_children_out_of_school\"]\/merged[\"f_pop\"]\n",
        "merged[\"m_out_of_school_rate\"] = merged[\"m_children_out_of_school\"]\/merged[\"m_pop\"]\n",
        "merged[\"Education Score\"] = (merged[\"m_labor_force_participation_rate\"]  \n",
        "                             + merged[\"f_labor_force_participation_rate\"] \n",
        "                             + merged[\"govt_expenditure_education\"] \n",
        "                             + merged[\"pupil_teacher_ratio\"]\n",
        "                             + merged[\"f_progression_to_secondary_school\"] \n",
        "                             + merged[\"m_progression_to_secondary_school\"]) - (merged[\"f_out_of_school_rate\"] + merged[\"m_out_of_school_rate\"] )\n",
        "merged = merged.dropna()"
      ],
      "execution_count":95,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "merged.to_csv('merged.csv')"
      ],
      "execution_count":96,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "### 3.2. Data Exploration"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "For the first two visualizations, we only used 14 countries. This selection process is shown below. The last two visualizations used the entire dataset."
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "bdi = merged[merged.country_code=='BDI']\n",
        "eth = merged[merged.country_code=='ETH']\n",
        "east_africa = bdi.merge(eth, how='outer')\n",
        "\n",
        "mli = merged[merged.country_code=='MLI']\n",
        "mrt = merged[merged.country_code=='MRT']\n",
        "west_africa = mli.merge(mrt, how='outer')\n",
        "\n",
        "lka = merged[merged.country_code=='LKA']\n",
        "ind = merged[merged.country_code=='IND']\n",
        "south_asia = lka.merge(ind, how='outer')\n",
        "\n",
        "kgz = merged[merged.country_code=='KGZ']\n",
        "kor = merged[merged.country_code=='KOR']\n",
        "east_asia = kgz.merge(kor, how='outer')\n",
        "\n",
        "mys = merged[merged.country_code=='MYS']\n",
        "phl = merged[merged.country_code=='PHL']\n",
        "southeast_asia = mys.merge(phl, how='outer') \n",
        "\n",
        "swe = merged[merged.country_code=='SWE']\n",
        "grc = merged[merged.country_code=='GRC']\n",
        "europe = swe.merge(grc, how='outer') \n",
        "\n",
        "ven = merged[merged.country_code=='VEN']\n",
        "col = merged[merged.country_code=='COL']\n",
        "south_america = ven.merge(col, how='outer') \n",
        "\n",
        "two = east_africa.merge(west_africa, how='outer')\n",
        "three = two.merge(south_asia, how='outer')\n",
        "four = three.merge(east_asia, how='outer')\n",
        "five = four.merge(southeast_asia, how='outer')\n",
        "six = five.merge(europe, how='outer')\n",
        "merged_14 = six.merge(south_america, how='outer')\n",
        "merged_14.sort_values(by='year', inplace=True)\n",
        "merged_14.to_csv('merged14.csv')"
      ],
      "execution_count":97,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "merged = pd.read_csv(\"https:\/\/raw.githubusercontent.com\/khushimorparia\/DS3000_FinalProject_FP4\/main\/merged.csv\")\n",
        "merged_14.to_csv('merged_14.csv')"
      ],
      "execution_count":98,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "import plotly.express as px\n",
        "\n",
        "line = px.line(merged_14, x=\"year\", y=\"Education Score\", line_group = \"country_name\", color = \"country_name\", \n",
        "              title='Education Scores from 1970 to 2020', template=\"none\")\n",
        "\n",
        "line.show()"
      ],
      "execution_count":113,
      "outputs":[
        {
          "data":{
            "text\/plain":[
              "Unsupported"
            ]
          },
          "metadata":{
            
          },
          "output_type":"display_data"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "<a href=\"https:\/\/ibb.co\/vY6SwjC\"><img src=\"https:\/\/i.ibb.co\/FVLFxDk\/newplot.png\" alt=\"newplot\" border=\"0\" width=800><\/a><br \/><a target='_blank' href='https:\/\/imgbb.com\/'><\/a><br \/>"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "This graph is displaying the education scores of 14 different countries from 1970 to 2020. It shows the trends in education levels for thos countries across 30 years."
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "merged_14[\"pop\"] = merged_14[\"m_pop\"] + merged_14[\"f_pop\"]"
      ],
      "execution_count":100,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "import plotly.express as px\n",
        "\n",
        "scatterplot = px.scatter(merged_14, x=\"country_code\", y=\"Education Score\", size = \"pop\", color = \"country_name\", animation_group = \"country_code\",\n",
        "                    hover_name = \"country_code\", size_max = 70,\n",
        "                    title='Education Score of Various Countries')\n",
        "\n",
        "#modify axis label properties\n",
        "scatterplot.update_xaxes(title_font={\"size\":18, \"family\": \"Courier\", \"color\":\"gray\"}, \n",
        "                 tickfont = {\"size\":16, \"family\": \"Courier\", \"color\":\"gray\"})\n",
        "scatterplot.update_yaxes(title_font={\"size\":18, \"family\": \"Courier\", \"color\":\"gray\"}, \n",
        "                            tickfont = {\"size\":16, \"family\": \"Courier\", \"color\":\"gray\"})\n",
        "\n",
        "scatterplot.show()\n",
        "\n"
      ],
      "execution_count":114,
      "outputs":[
        {
          "data":{
            "text\/plain":[
              "Unsupported"
            ]
          },
          "metadata":{
            
          },
          "output_type":"display_data"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "<a href=\"https:\/\/ibb.co\/NrhBzqd\"><img src=\"https:\/\/i.ibb.co\/5kDHV3g\/newplot-2.png\" alt=\"newplot-2\" border=\"0\" width=800><\/a><br \/><a target='_blank' href='https:\/\/imgbb.com\/'><\/a><br \/>"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "The above scatter plot visualizes the relationships of different education scores amongst different countries and how they vary from one another. The size of the bubble is proportionate to the population of the country, where a larger circle represents a higher population."
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "merged = pd.read_csv(\"https:\/\/raw.githubusercontent.com\/khushimorparia\/DS3000_FinalProject_FP4\/main\/merged.csv\")\n",
        "l = merged.loc[(merged.year == 2020)][\"Education Score\"]\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure(figsize =(10, 7))\n",
        "plt.boxplot(l, vert=False)\n",
        "plt.xlabel(\"Education Score\")\n",
        "ax = plt.gca()\n",
        "ax.axes.yaxis.set_visible(False)\n",
        "plt.title(\"2020 Education Score Distribution\")\n",
        "plt.show()"
      ],
      "execution_count":116,
      "outputs":[
        {
          "data":{
            "image\/png":[
              "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\n"
            ]
          },
          "metadata":{
            "image\/png":{
              
            }
          },
          "output_type":"display_data"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "<a href=\"https:\/\/ibb.co\/Wxq4KBX\"><img src=\"https:\/\/i.ibb.co\/mD1VzhK\/Screen-Shot-2021-12-10-at-3-13-53-PM.png\" alt=\"Screen-Shot-2021-12-10-at-3-13-53-PM\" border=\"0\"><\/a><br \/><a target='_blank' href='https:\/\/imgbb.com\/'><\/a><br \/>"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "This boxplot exhibits the variance of education scores across all countries in 2020. It allows us to see the average education score, the low, high, and the first and third quartiles, and the outliers of education scores."
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "merged = pd.read_csv(\"https:\/\/raw.githubusercontent.com\/khushimorparia\/DS3000_FinalProject_FP4\/main\/merged.csv\")\n",
        "import plotly.express as px\n",
        "\n",
        "world = px.choropleth(merged, locations=\"country_name\",\n",
        "                    locationmode = 'country names',\n",
        "                    color=\"Education Score\",\n",
        "                    hover_name=\"country_name\",\n",
        "                    title = \"Education Scores\",\n",
        "                    animation_frame = \"year\")\n",
        "world.show()"
      ],
      "execution_count":117,
      "outputs":[
        {
          "data":{
            "text\/plain":[
              "Unsupported"
            ]
          },
          "metadata":{
            
          },
          "output_type":"display_data"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "#### 1970:\n",
        "<a href=\"https:\/\/ibb.co\/q1bzw5m\"><img src=\"https:\/\/i.ibb.co\/vz2b8YL\/newplot-3.png\" alt=\"newplot-3\" border=\"0\" width= 700><\/a><br \/><a target='_blank' href='https:\/\/imgbb.com\/'><\/a><br \/>\n",
        "#### 2020:\n",
        "<a href=\"https:\/\/ibb.co\/LdwG5jG\"><img src=\"https:\/\/i.ibb.co\/s9SBHxB\/newplot-4.png\" alt=\"newplot-4\" border=\"0\" width= 700><\/a><br \/><a target='_blank' href='https:\/\/imgbb.com\/'><\/a><br \/>"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "The above choropleth graph animation shows the education scores of different countries throughout every recorded year in our dataset. "
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "### 3.3. Model Training"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "We used 4 different machine learning algorithms for our regression problem: Linear Regression, Lasso, Ridge, and K-Nearest Neighbors."
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "estimators = {\"Linear Regression\": LinearRegression(),\n",
        "              \"Lasso\": Lasso(),\n",
        "              \"Ridge\": Ridge(),\n",
        "              \"K-Nearest Neighbors\": KNeighborsRegressor(n_neighbors = 8)}"
      ],
      "execution_count":106,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "We then split the dataset into features and target and then training and testing sets."
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "features = merged[[\"f_labor_force_participation_rate\", \"m_labor_force_participation_rate\"\n",
        ",\"govt_expenditure_education\", \"pupil_teacher_ratio\", \"f_progression_to_secondary_school\", \"m_progression_to_secondary_school\"\n",
        ", \"f_children_out_of_school\", \"m_children_out_of_school\", \"f_out_of_school_rate\", \"m_out_of_school_rate\"]]\n",
        "target = pd.Series(merged[\"Education Score\"])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, target, random_state=3000)"
      ],
      "execution_count":107,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "After that, we ran the algorithms on our data, for a baseline comparison"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "from sklearn.metrics import r2_score\n",
        "\n",
        "def r2_scores():\n",
        "    for est_key, est_obj in estimators.items():\n",
        "        model = est_obj.fit(X=X_train, y=y_train)\n",
        "\n",
        "        train = r2_score(y_train, model.predict(X_train))\n",
        "        test = r2_score(y_test, model.predict(X_test))\n",
        "\n",
        "        print(est_key + \":\", \"\\n\tR-squared value on training set:  \" + str(train))\n",
        "        print (\"\\tR-squared value on testing set:  \" + str(test) + \"\\n\")\n",
        "r2_scores()"
      ],
      "execution_count":108,
      "outputs":[
        {
          "name":"stdout",
          "text":[
            "Linear Regression: \n",
            "\tR-squared value on training set:  1.0\n",
            "\tR-squared value on testing set:  1.0\n",
            "\n",
            "Lasso: \n",
            "\tR-squared value on training set:  0.9990553099729736\n",
            "\tR-squared value on testing set:  0.9991294965528814\n",
            "\n",
            "Ridge: \n",
            "\tR-squared value on training set:  0.9999999798744033\n",
            "\tR-squared value on testing set:  0.9999999775810816\n",
            "\n",
            "K-Nearest Neighbors: \n",
            "\tR-squared value on training set:  0.6727194915093648\n",
            "\tR-squared value on testing set:  0.5395824732961989\n",
            "\n"
          ],
          "output_type":"stream"
        },
        {
          "name":"stderr",
          "text":[
            "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_ridge.py:156: LinAlgWarning:\n",
            "\n",
            "Ill-conditioned matrix (rcond=1.66698e-18): result may not be accurate.\n",
            "\n",
            "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/base.py:441: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
            "\n",
            "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/base.py:441: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
            "\n"
          ],
          "output_type":"stream"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "As shown from the output above, Linear Regression, Lasso, Ridge and kNN were all overfitting. We then went in and scaled the features."
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(X_train)\n",
        "\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "def scaling():\n",
        "    for est_key, est_obj in estimators.items():\n",
        "        model = est_obj.fit(X=X_train_scaled, y=y_train)\n",
        "\n",
        "        train = r2_score(y_train, model.predict(X_train_scaled))\n",
        "        test = r2_score(y_test, model.predict(X_test_scaled))\n",
        "\n",
        "        print(est_key + \":\", \"\\n\tR-squared value on training set:  \" + str(train))\n",
        "        print (\"\\tR-squared value on testing set:  \" + str(test) + \"\\n\")\n",
        "scaling()"
      ],
      "execution_count":109,
      "outputs":[
        {
          "name":"stdout",
          "text":[
            "Linear Regression: \n",
            "\tR-squared value on training set:  1.0\n",
            "\tR-squared value on testing set:  1.0\n",
            "\n",
            "Lasso: \n",
            "\tR-squared value on training set:  0.6753954659046641\n",
            "\tR-squared value on testing set:  0.684399327547452\n",
            "\n",
            "Ridge: \n",
            "\tR-squared value on training set:  0.999846067616889\n",
            "\tR-squared value on testing set:  0.9998492210070818\n",
            "\n",
            "K-Nearest Neighbors: \n",
            "\tR-squared value on training set:  0.9815114932291927\n",
            "\tR-squared value on testing set:  0.970087070229972\n",
            "\n"
          ],
          "output_type":"stream"
        },
        {
          "name":"stderr",
          "text":[
            "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/base.py:441: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but LinearRegression was fitted with feature names\n",
            "\n",
            "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/base.py:441: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but LinearRegression was fitted with feature names\n",
            "\n",
            "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/base.py:441: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but Lasso was fitted with feature names\n",
            "\n",
            "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/base.py:441: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but Lasso was fitted with feature names\n",
            "\n",
            "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/base.py:441: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but Ridge was fitted with feature names\n",
            "\n",
            "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/base.py:441: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but Ridge was fitted with feature names\n",
            "\n",
            "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/base.py:441: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
            "\n",
            "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/base.py:441: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
            "\n",
            "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/base.py:441: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
            "\n",
            "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/base.py:441: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
            "\n"
          ],
          "output_type":"stream"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "As shown from the output above, all three models besides Lasso overfitted after scaling. However, kNN showed the best results without considerable overfitting so we decided to use it for feature selection and model optimization."
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "def RFE_feature_selection():  \n",
        "    from sklearn.feature_selection import RFE\n",
        "    from sklearn.tree import DecisionTreeRegressor\n",
        "    from sklearn.metrics import r2_score\n",
        "\n",
        "    select = RFE(DecisionTreeRegressor(random_state = 3000), n_features_to_select = 3)\n",
        "    select.fit(X_train, y_train)\n",
        "\n",
        "    X_train_selected = select.transform(X_train_scaled)\n",
        "    X_test_selected = select.transform(X_test_scaled)\n",
        "    \n",
        "    model = KNeighborsRegressor().fit(X=X_train_selected, y=y_train)\n",
        "    r_squared_training = r2_score(y_train, model.predict(X_train_selected))\n",
        "    r_squared_test = r2_score(y_test, model.predict(X_test_selected))\n",
        "        \n",
        "    print(\"Selected features after RFE:\")\n",
        "    for item, value in zip(features.columns, select.get_support()):\n",
        "        if value:\n",
        "            print(f'\\t\\t{item}')\n",
        "    \n",
        "    print(\"kNN Regression performance with selected features: \\n\\t\" + f'R-squared value for training set: {r_squared_training}' + \"\\n\\t\"\n",
        "             + f'R-squared value for testing set: {r_squared_test}' + \"\\n\")\n",
        "    return (X_train_selected, X_test_selected)\n",
        "X_train_selected, X_test_selected = RFE_feature_selection()"
      ],
      "execution_count":110,
      "outputs":[
        {
          "name":"stdout",
          "text":[
            "Selected features after RFE:\n",
            "\t\tf_labor_force_participation_rate\n",
            "\t\tm_labor_force_participation_rate\n",
            "\t\tm_progression_to_secondary_school\n",
            "kNN Regression performance with selected features: \n",
            "\tR-squared value for training set: 0.9731359723010324\n",
            "\tR-squared value for testing set: 0.9536563929909451\n",
            "\n"
          ],
          "output_type":"stream"
        },
        {
          "name":"stderr",
          "text":[
            "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/base.py:441: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but RFE was fitted with feature names\n",
            "\n",
            "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/base.py:441: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but RFE was fitted with feature names\n",
            "\n"
          ],
          "output_type":"stream"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "The model still overfitted, although it is still close. In order to further improve accuracy, we did hyperparameter tuning, as shown below."
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "### 3.4. Model Optimization"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# this function applies a Grid Search with kNN regression estimator and \n",
        "# evaluates the performance of these parameters using a 5-fold evaluation\n",
        "def tuning():\n",
        "    param_grid = dict(n_neighbors= [1,5,10], metric=[\"euclidean\",\"manhattan\",\"minkowski\"])\n",
        "    grid_search = GridSearchCV(KNeighborsRegressor(), param_grid, cv = 5)\n",
        "    grid_search.fit(X=X_train_selected, y=y_train)\n",
        " \n",
        "    print(\"Best parameters: \", grid_search.best_params_)\n",
        "tuning()"
      ],
      "execution_count":111,
      "outputs":[
        {
          "name":"stdout",
          "text":[
            "Best parameters:  {'metric': 'manhattan', 'n_neighbors': 5}\n"
          ],
          "output_type":"stream"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "We did this to determine which parameters would ensure the best predictive accuracy with the least overfitting of the training model. THen, we tested the feature-selected model with these parameters below."
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "### 3.5. Model Testing"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "model = KNeighborsRegressor().set_params(metric='manhattan', n_neighbors=5).fit(X=X_train_selected, y=y_train)\n",
        "r_squared_training = r2_score(y_train, model.predict(X_train_selected))\n",
        "r_squared_test = r2_score(y_test, model.predict(X_test_selected))\n",
        "print(\"kNN Regression performance with tuned algorithm: \\n\\t\" + f'R-squared value for training set: {r_squared_training}' + \"\\n\\t\"\n",
        "             + f'R-squared value for testing set: {r_squared_test}' + \"\\n\")"
      ],
      "execution_count":112,
      "outputs":[
        {
          "name":"stdout",
          "text":[
            "kNN Regression performance with tuned algorithm: \n",
            "\tR-squared value for training set: 0.9736340816508632\n",
            "\tR-squared value for testing set: 0.9540568863004767\n",
            "\n"
          ],
          "output_type":"stream"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "Although the training set is still overfitting, the accuracy of the testing set increased. This means that the model is not the best for our data, but it is still relatively good because both accuracies are above 95%."
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "<a id=\"4\"><\/a>\n",
        "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "## 4. DISCUSSION\n",
        "We compared Linear Regression, Lasso regression, Ridge regression, and K-Nearest Neighbor regression on our dataset. KNN had 8 nearest neighbors, and the other three algorithms had no parameters. Linear regression, lasso, and ridge were all overfitting.\n",
        "KNN performed the best even though it technically had the lowest R2 score of all. KNN was the only algorithm that performed as expected. After scaling and feature engineering, the R2 scores for the KNN algorithm increased significantly. Because of this, we will be using KNN for our predictive model. \n",
        "\n",
        "Based on our findings, we can use the features in our dataset to predict the education score. \n",
        "\n",
        "### Ethics\n",
        "There are several potential ethical implications that arise with the findings of our project. Our aim for this project was to quantify a country’s education level so we could make inferences about a country’s current and future performance. That being said, education is not something that is easily quantifiable and our data can be misinterpreted because of that. Moreover, we may be under or overestimating a country’s actual performance, which may be demeaning to the people in countries with a low education score. Our project gives one perspective of education levels and is taking just a few measures into account.  \n",
        "\n",
        "### Future Adaptations\n",
        "In the future, we would like to expand our dataset to include more countries. Right now, our data is missing the United States, New Zealand, Vietnam, Australia, Chad, France, and more which we feel are important to our data and results. \n",
        "Overall, we believe that a better dataset would improve our analysis, as we are missing important educational factors such as literacy rate and spending per student. \n",
        "Another thing we’d be interested in doing is looking at correlations between a country’s education score and other success measures such as their gross domestic product (GDP), per capita income, national health rate, government type, crime rate, or more. Education is an underlying factor that affects most of these measures, so studying their correlation would be very insightful. "
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "<a id=\"5\"><\/a>\n",
        "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "### CONTRIBUTIONS\n",
        "Khushi wrote the executive summary and part of the data analysis section, created the line graph visualization, and coded for model training, model optimization, and model testing. Priyanka wrote the introduction, methods, and a part of data analysis, created the scatterplot visualization, and coded for model optimization. Katerina wrote the discussion and part of the introduction, created the box-and-whisker plot and choropleth visualizations, and coded for the model training. We all collectively gathered the data and worked on data wrangling. "
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    }
  ],
  "metadata":{
    
  },
  "nbformat":4,
  "nbformat_minor":0
}